---
sidebar_position: 1
---

# 1장 파운데이션 모델을 활용한 AI 애플리케이션 입문  

- [1장 파운데이션 모델을 활용한 AI 애플리케이션 입문](#1장-파운데이션-모델을-활용한-ai-애플리케이션-입문)
  - [\_1.1 AI 엔지니어링의 부상](#_11-ai-엔지니어링의-부상)
  - [\_1.2 파운데이션 모델 활용 사례](#_12-파운데이션-모델-활용-사례)
  - [\_1.3 AI 애플리케이션 기획](#_13-ai-애플리케이션-기획)
  - [1.4 AI 엔지니어링 스택](#14-ai-엔지니어링-스택)


이 책에서는 AI 엔지니어링의 범주에서 지식 습득  
- AI 엔지니어링은 파운데이션 모델을 활용해 제품까지 만드는 전반적인 엔지니어링 기술을 커버한다.  
- 1, 파운데이션 모델에 대한 이해 : 모델 아키텍처, 사후 학습, 샘플링  
- 2, 평가 방법론, 평가 기준, 평가 프레임워크 설계하기 
- 3, 프롬프트 엔지니어링
- 4, RAG, Agent  
- 5, 파인튜닝  
- 6, 데이터셋 엔지니어링  
- 7, 추론 최적화 : 지식 증류(Knowledge Distillation)
- 8, AI 엔지니어링 아키텍처, 사용자 피드백  

## _1.1 AI 엔지니어링의 부상

📌 __1.1.1 언어 모델에서 대규모 언어 모델로

언어 모델 : 언어의 통계적 특성을 이용해 예측하는 모델   
- 통계적 언어 모델 (SLM): 지금까지 사람들이 쓴 글 중에서, 이 단어 뒤에 어떤 단어가 가장 자주 나왔지? 를 통계낸다.  
  - 단점 : 긴 문맥 파악 불가, 데이터에 없는 표현은 예측 불가.  
  - 예, N-gram 모델 (스마트폰 키보드 자동 추천, 검색 엔진의 자동 완성)
- 신경망 언어 모델 (NNLM)
  - 토큰화 : 모델 이해가능한 최소 의미 단위로 분리하는 것.  
  - 어휘 : 모든 토큰의 집합이다.  
  - 토큰화의 장점 : 문자를 의미있는 구성 단위로 나눈다. / 고유 단어보다 적게 토큰이 나오므로 모델이 더 효율적 처리 / gpting 등 gpt, ing 로 나누어 모르는 단어를 처리 할 수 있다. 

Masked language model 
- BERT : Bidirectional Encoder Representations from Transformers
- BERT, GPT 모두 트랜스포머(Transformer)라는 혁신적인 설계도에서 탄생한 형제 모델.  
  - Bidirectional (양방향): 문장을 읽을 때 왼쪽에서 오른쪽, 오른쪽에서 왼쪽 양쪽 방향을 동시에 봅니다. 덕분에 문맥을 아주 깊게 이해합니다.
  - Encoder (인코더): 트랜스포머의 구조 중 입력된 정보를 해석하고 압축하는 '인코더' 부분만 사용했다는 뜻입니다.
  - Representations (표현): 단어의 의미를 컴퓨터가 이해할 수 있는 수치(벡터)로 아주 잘 **'표현'**해낸다는 의미입니다.
  - from Transformers: 이 모든 것이 트랜스포머 기술 덕분에 가능했다는 출처를 밝히는 것입니다.
  - [요약] "트랜스포머를 이용해 문맥을 양방향으로 깊게 이해하고 수치로 표현하는 모델"

Autoregressive Model  
- GPT  Generative Pre-trained Transformer
  - Generative (생성형): 문장을 이해하는 데서 그치지 않고, 새로운 문장을 **'생성'**하는 데 특화되어 있습니다.
  - Pre-trained (사전 학습된): 특정 작업을 시키기 전에 이미 인터넷상의 방대한 데이터를 미리 공부해서 **'기초 지식이 쌓여 있다'**는 뜻입니다.
  - Transformer (트랜스포머): 역시 핵심 엔진은 트랜스포머라는 의미입니다. (구체적으로는 '디코더' 부분을 사용합니다.)

자기 지도 학습 
- 지도 학습은 직접 정답셋 구축을 위한 레이블링 작업이 필요하다.  
- 자기 지도 학습은 레이블링 병목을 제거해준다.  

📌 __1.1.2 대규모 언어 모델에서 파운데이션 모델로  

모달리티란? : AI에게도 어떤 형태의 데이터를 입력받고 출력하는지가 바로 모달리티  
- Text, Image, Audio, Video 등 형태가 있음  
- 멀티모달(Multi-modal) : 여러 개의 모달리티를 동시에 처리하는 것    
- 멀티모달 모델 (Multi-modal Model) : 여러 감각(텍스트, 이미지, 소리 등)을 동시에 사용하는 모델  
- 파운데이션 모델 (Foundation Model) : 하나의 모델로 수만 가지 일을 할 수 있게 만든 기본 모델    

이미지 모델 CLIP는 어떻게 자기 지도 학습이 가능?  
- CLIP(Contrastive Language-Image Pre-training)  
- 인터넷의 방대한 텍스트-이미지 쌍 4억 활용  
- 이미지 인코더: 사진의 특징을 추출합니다. (Vision Transformer 등 사용)
- 텍스트 인코더: 글의 의미를 추출합니다. (위에서 배운 BERT/GPT 같은 트랜스포머 기반)
- 위 2개의 쌍 정보를 하나의 공통된 공간(임베딩 공간)에 모아둔다. 이를 정답셋으로 간주
- 정답셋에서 랜덤하게 쌍을 뽑아 "이 사진과 이 문장이 같은 의미인가?"를 계속해서 맞춰보면서 자기 지도 학습  

파운데이션 모델을 개조하는게 더 낫다.  
- 기존에는 감정 분석 특화, 번역 특화 모델을 각각 개발 했음. 데이터 구축과 학습 비용이 크다.  
- 큰 규모의 언어 모델(파운데이션)을 가지고  프롬프트 엔지니어링, RAG, 파인 튜닝으로 더 적은 데이터 셋으로 개조하는게 훨씬 적은 비용이다.  

📌 __1.1.3 파운데이션 모델에서 AI 엔지니어링으로  

- ML 엔지니어링 : ML 모델을 자체 개발  
- AI 엔지니어링 : 파운데이션 모델을 활용하여 응용어플레케이션단을 개발 하는 것 


--- 

## _1.2 파운데이션 모델 활용 사례  
- AI가 생성하는 무작위적인 창작물을 불신하므로, 신뢰하는 사람과 브랜드가 더 중요해 진다.  
- 코딩, 이미지 및 동영상 제작, 글쓰기, 교육, 대화형 봇, 정보 집계, 데이터 체계화, 워크플로 자동화  


## _1.3 AI 애플리케이션 기획

1, AI 제품의 3대 해자 (Moat)  
- 전통적인 소프트웨어와 달리 AI 제품은 단순히 기능을 만드는 것보다 방어력을 갖추는 것이 훨씬 어렵습니다.
- 1-1, 기술력 (파운데이션 모델의 흡수): 
  - PDF 변환 레이어를 추가한 AI 제품을 만들었으나, 파운데이션모델이 이를 곧 흡수
  - 특정 기능을 구현하는 기술은 시간이 지나면 파운데이션 모델(GPT, Gemini 등)의 기본 기능으로 포함되거나, 더 저렴한 오픈소스 모델이 나오면서 가치가 하락합니다.
- 1-2, 데이터 (Proprietary Data): 인터넷에 공개된 데이터가 아니라, 우리 서비스 안에서만 발생하는 **사용자 행동 데이터나 전문적인 피드백 루프(Flywheel)**가 진짜 해자가 됩니다.
- 1-3, 유통력 (Distribution): 사용자가 이미 머물고 있는 플랫폼(Slack, Notion, Google Workspace 등)에 얼마나 깊숙이 침투해 있느냐가 핵심입니다. 
  - 기술이 비슷하다면 결국 이미 결제하고 있는 서비스 안의 기능을 쓰게 되기 때문입니다.

2, 스타트업 기능의 대기업 통합 사례 (Bundle vs Unbundle)  
- (캘린들리 > 구글캘린더 / 메일침프 > GMail / 포토룸 > 구글 포토)  

3, 비즈니스 및 기술적 측정 목표 (Metrics)
- AI 제품은 정성적인 '똑똑함'보다 **정량적인 '수치'**로 증명해야 합니다.
- 비즈니스 지표: 고객 지원 티켓 30% 자동화 -> 60% 자동화 목표   
- 기술적 지표 (Performance):
  - TTFT (Time to First Token): 첫 글자가 나오는 속도 (사용자 경험의 핵심).
  - TPS (Tokens Per Second): 전체 출력 속도.
  - 정확도(Accuracy) 및 신뢰도: 환각(Hallucination) 발생률 관리.

4, 마일스톤 계획 : 80/20 법칙의 함정
- AI 앱은 구현(0%→80%)은 쉽지만, 상용화(80%→99%)는 지옥
- 초기 단계 (1개월): API 연동만으로 그럴듯한 프로토타입이 나옵니다.
- 개선 단계 (무한 루프): 예외 상황 처리, 엣지 케이스(Edge case) 대응, 정확도 5%를 올리기 위해 데이터셋을 새로 구축하고 파인튜닝을 반복하는 과정에서 수개월이 소요됩니다.
- 교훈: 처음부터 100%를 목표로 하기보다, 80%의 성능으로도 가치를 줄 수 있는 영역부터 공략  

5, 유지보수 계획 : 직접 서빙 vs API (Trade-off)
- 새로운 모델이 매주 쏟아지는 환경에서 인프라 결정은 매우 중요합니다.
- API 사용 (OpenAI 등): 관리 부담이 적고 최신 모델 적용이 빠르지만, 비용이 비싸고 데이터 보안 및 서비스 종속성 문제가 있습니다.
- 직접 서빙 (vLLM, Triton 등): 초기 인프라 구축 비용(GPU)과 인력이 많이 들지만, 장기적으로 비용이 저렴해지고 데이터 보안을 완벽히 통제할 수 있습니다.



## 1.4 AI 엔지니어링 스택

AI의 세 가지 계층  
1. Application 계층 (서비스 중심) : 사용자가 AI를 실제로 경험하는 단계입니다. 단순히 UI를 만드는 것을 넘어, **'AI가 어떻게 답변할지'**를 설계하는 것이 핵심.  
- AI UI/UX: 챗봇 형태, 에이전트 인터페이스 등 사용자 접점 설계.  
- Context 구성 (RAG): AI가 모르는 정보를 외부 문서(DB)에서 찾아와 전달해주는 시스템 설계.  
- Prompt Engineering: 답변의 품질과 톤을 결정하는 지시문 설계.  
- 평가 (Ops): 사용자의 피드백을 수집하고 답변의 유해성이나 정확도를 평가.  

1. Model 계층 (지능 중심) : AI의 두뇌 자체를 만들거나 최적화하는 단계입니다. 우리가 앞서 이야기한 추론 최적화가 바로 여기에 해당합니다.
- 데이터셋 엔지니어링: 학습을 위한 양질의 데이터를 수집, 정제, 라벨링.
- 모델링과 학습: 파인튜닝(Fine-tuning)이나 지식 증류(Distillation)를 통해 특정 목적에 맞는 모델 제작.
- 추론 최적화: 양자화(Quantization) 등을 통해 모델을 가볍고 빠르게 변환.
- 평가: 모델의 벤치마크 점수나 성능 지표(Perplexity 등) 관리.

1. Infra 계층 (기반 중심) : AI가 돌아갈 수 있는 '땅'과 '전기'를 공급하는 단계입니다.
- 컴퓨팅 리소스: GPU/NPU 서버 관리 및 클러스터 구성.
- 데이터 관리: 대규모 벡터 데이터베이스(Vector DB)나 데이터 레이크 운영.
- 서빙 (Serving): API 형태로 모델을 외부에 연결하고, 트래픽을 분산 처리.
- 모니터링: 시스템 부하, 비용(GPU 사용량), 모델의 지연 시간(Latency) 관리.

---

모델 조정
- 1. 프롬프트 엔지니어링: 파라미터 조정이나 데이터셋 필요 없이 지시문만으로 결과를 제어하는 방식입니다. 모델의 가중치를 건드리지 않는 외부적인 접근법입니다.
- 2. 파인 튜닝: 모델의 가중치를 사전 학습 이후 특정 목적에 맞게 조정하는 것입니다. 상대적으로 적은 데이터셋으로도 특정 분야의 성능을 높일 수 있습니다.
- 3. 사후 학습: 파인 튜닝과 기술적으로는 유사하지만, 주로 모델 제공자가 사전 학습 직후에 진행하는 정렬 작업을 의미합니다. 
  - 인간의 피드백을 반영하는 RLHF나 안전성 확보 과정이 여기에 해당합니다.
- 4. 사전 학습: 모델의 파라미터를 무작위로 설정한 후 처음부터 대규모 데이터를 학습시키는 과정입니다.   
  - 전체 리소스의 대부분이 소모되며, 막대한 자본이 투입되므로 설계 오류 시 재정적 타격이 매우 큽니다. (전체 학습의 과정 중 98%의 리소스가 소모)    

데이터셋 엔지니어링
1. 모델 학습에 필요한 데이터를 수집, 관리하고 품질을 유지하는 작업입니다.
2. 과거와 달리 주관식 답변이 필요한 비정형 데이터가 중심이 되므로, 정답이 정해진 데이터보다 관리 난이도가 훨씬 높습니다.  

전통적인 ML과 풀스택 엔지니어의 차별성  
- ML 엔지니어는 데이터 -> 모델 -> 제품을 만드는 순서로 접근한다면,  
- 풀스택 엔지니어는 제품 관점에서 아이디어를 빠르게 구현해보고 개선하는 측에 장점이 있다.   