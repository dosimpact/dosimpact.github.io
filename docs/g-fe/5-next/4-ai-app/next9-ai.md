---
sidebar_position: 9
---

# AI SDK    

- [AI SDK](#ai-sdk)
  - [ì£¼ìš” í•¨ìˆ˜ë“¤](#ì£¼ìš”-í•¨ìˆ˜ë“¤)
  - [Stream Protocols](#stream-protocols)
  - [ğŸ“Œ Basic](#-basic)
  - [ğŸ“Œ Generative User Interfaces](#-generative-user-interfaces)
  - [ğŸ“Œ Streaming Custom Data](#-streaming-custom-data)
    - [eg) ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½í•˜ê¸°](#eg-ìŠ¤í¬ë¦½íŠ¸-ìš”ì•½í•˜ê¸°)
    - [eg) ë§ˆí¬ ë‹¤ìš´ ë¬¸ì„œ Streaming ì‘ë‹µ](#eg-ë§ˆí¬-ë‹¤ìš´-ë¬¸ì„œ-streaming-ì‘ë‹µ)
    - [eg) ë¬¸ì„œë¥¼ ì²¨ì‚­ Streaming Object](#eg-ë¬¸ì„œë¥¼-ì²¨ì‚­-streaming-object)


## ì£¼ìš” í•¨ìˆ˜ë“¤  

>Blocking UI vs Streaming UI : https://sdk.vercel.ai/docs/foundations/streaming  

- generateText : Blocking UI + text
- generateObject : Blocking UI + object  
  - https://sdk.vercel.ai/docs/advanced/sequential-generations  
- streamObject : Streaming UI + text
- streamText : Streaming UI + object
- createDataStreamResponse : Streaming UI + Streaming Custom Data  


## Stream Protocols  

>https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol  

stream protocol ì´ë€?  
- HTTP í”„ë¡œí† ì½œ ìœ„ì—ì„œ ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ë¥¼ ë„˜ê¸°ëŠ” ê·œì¹™. ( text stream, data stream ëª¨ë‘ í¬í•¨ )  

Text Stream Protocol
- `streamText().toTextStreamResponse();`   ì‚¬ìš©  

Data Stream Protocol
- `createDataStreamResponse` ì‚¬ìš©    

*íƒ€ì… êµ¬ë¶„ì„ í†µí•´ì„œ Stream Protocol ë‚´ Text, Data ëª¨ë‘ ë‚´ë ¤ì˜¬ ìˆ˜ ìˆë‹¤.   

*TypeID = 0,  Text Part  
- Format: 0:string\n  

*TypeID = 2,  Data Part  
- Format: 2:[{"key":"object1"},{"anotherKey":"object2"}]\n  

*TypeID = 8,  Message Annotation Part  
- Format: 8:[{"id":"message-123","other":"annotation"}]\n   

*TypeID = 3,  Error Part
- Format: 3:"error message"\n    

*TypeID = 3,  Tool Call Streaming Start Part
- Format: b:{"toolCallId":"call-456","toolName":"streaming-tool"}\n      
*TypeID = c,  Tool Call Delta Part
- Format: c:{"toolCallId":"call-456","argsTextDelta":"partial arg"}\n
*TypeID = 9,  Tool Call Part
- Format: 9:{"toolCallId":"call-123","toolName":"my-tool","args":{"some":"argument"}}\n
*TypeID = a,  Tool Result Part
- Format: a:{"toolCallId":"call-123","result":"tool output"}\n

*TypeID = e,  Finish Step Part
- Format: e:{"finishReason":"stop","usage":{"promptTokens":10,"completionTokens":20},"isContinued":false}\n
*TypeID = d,  Finish Message Part
- Format: d:{"finishReason":"stop","usage":{"promptTokens":10,"completionTokens":20}}\n

```
// ì‘ë‹µ ì˜ˆ 
// TypeID, Type delimiter(:), Text|Data Chunk, Chunk delimiter 4ê°€ì§€ íŒŒíŠ¸ë¡œ êµ¬ì„±  

2:["initialized call"]
8:[{"chunk":"123"}]
0:"Hello"
8:[{"chunk":"123"}]
0:"!"
8:[{"chunk":"123"}]
0:" How"
8:[{"chunk":"123"}]
0:" can"
8:[{"chunk":"123"}]
0:" I"
8:[{"chunk":"123"}]
0:" assist"
8:[{"chunk":"123"}]
0:" you"
8:[{"chunk":"123"}]
0:" today"
8:[{"chunk":"123"}]
0:"?"
8:[{"id":"DU5YpIiiuczDZpiN","other":"information"}]
2:["call completed"]
e:{"finishReason":"stop","usage":{"promptTokens":8,"completionTokens":9},"isContinued":false}
d:{"finishReason":"stop","usage":{"promptTokens":8,"completionTokens":9}}
```




## ğŸ“Œ Basic

```js
// app/api/chat-test/route.ts
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

export async function POST(request: Request) {
  const { messages } = await request.json();

  const result = streamText({
    model: openai("gpt-4o-mini"),
    system: "You are a friendly assistant!",
    messages,
    maxSteps: 5,
  });

  return result.toDataStreamResponse();
}
---
// chat-lite.tsx
"use client";

import { generateUUID } from "@/lib/utils";
import { useChat } from "ai/react";
import React from "react";

/*
[
    {
        "role": "user",
        "content": "my name is jay",
        "id": "bPclYKo27gxhIoWn",
        "createdAt": "2024-12-12T12:28:11.371Z"
    },
    {
        "id": "NPFi3J8vWw7Sa5uw", 
        "role": "assistant",
        "content": "Nice to meet you, Jay! How can I assist you today?",
        "createdAt": "2024-12-12T12:28:13.252Z",
        "revisionId": "pDmdPLtSHFUvn3Bi"
    }
]*/

const ChatLite = ({ id }: { id: string }) => {
  const {
    messages, // ì§€ê¸ˆê¹Œì§€ì˜ ëˆ„ì  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    setMessages, // ë©”ì‹œì§€ setter, (api call ì—†ìŒ)
    input, // ì‚¬ìš©ì ì…ë ¥ & setter
    setInput,
    handleSubmit, // inputì˜ ë‚´ìš©ì„ ëª¨ë¸ì— ì „ì†¡, messageê°ì²´ ì¶”ê°€, input ì´ˆê¸°í™”
    append, // ì‚¬ìš©ì message ì¶”ê°€ í›„ ë°”ë¡œ api í˜¸ì¶œ.
    isLoading,
    stop, // abort the current API
    data: streamingData, //ìµœê·¼ ì‘ë‹µë°ì´í„°ì˜ ìŠ¤íŠ¸ë¦¼
  } = useChat({
    api: "/api/chat",
    body: { id: id, modelId: "gpt-4o-mini" },
  });

  // send continue message
  console.log({ id, messages, streamingData });

  return (
    <div>
      <div>{JSON.stringify(messages)}</div>
      <input value={input} onChange={(e) => setInput(e.target.value)} />
      <button onClick={handleSubmit}>send</button>
      {/* append */}
      <div>
        <button
          onClick={() => append({ role: "user", content: "my name is jay" })}
        >
          Append suggested message!
        </button>
      </div>
    </div>
  );
};

export default ChatLite;
```

## ğŸ“Œ Generative User Interfaces

íë¦„  
- 1.tools ì •ì˜ í•˜ê¸° - description, parameters, execute    
  - ì˜ˆ, íŠ¹ì • ìœ„ì¹˜ì˜ ë‚ ì‹œë¥¼ ë³´ì—¬ì¤˜, ì¸ìê°’:location, ì‹¤í–‰í•¨ìˆ˜ - ë‚ ì”¨ API    
- 2.Router Handlerì— streamText ì‘ì„±í•˜ê¸°    
- 3.messages ì¤‘ toolInvocations í•„ë“œë¥¼ ë³´ê³  UIë¥¼ ëœë”ë§ í•˜ê¸°    

ì œì•½
- gpt-4o-mini, gpt-4 ì´ìƒ ëª¨ë¸ ì„ íƒ  


```js
//lib/ai/tools.ts
import { tool as createTool } from "ai";
import { z } from "zod";

export const weatherTool = createTool({
  description: "Display the weather for a location",
  parameters: z.object({
    location: z.string(),
  }),
  execute: async function ({ location }) {
    await new Promise((resolve) => setTimeout(resolve, 2000));
    return { weather: "Sunny", temperature: 75, location };
  },
});

export const tools = {
  displayWeather: weatherTool,
};

---
// app/api/chat-test/route.ts
import { tools } from "@/lib/ai/tools";
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

export async function POST(request: Request) {
  const { messages } = await request.json();

  const result = streamText({
    model: openai("gpt-4o-mini"),
    system: "You are a friendly assistant!",
    messages,
    maxSteps: 5,
    tools,
  });

  return result.toDataStreamResponse();
}
```

```js
// components/chat-lite-ui
"use client";

import { useChat } from "ai/react";

type WeatherProps = {
  temperature: number;
  weather: string;
  location: string;
};

export const Weather = ({ temperature, weather, location }: WeatherProps) => {
  return (
    <div>
      <h2>Current Weather for {location}</h2>
      <p>Condition: {weather}</p>
      <p>Temperature: {temperature}Â°C</p>
    </div>
  );
};

const ChatLiteUI = () => {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: "/api/chat-test",
  });

  console.log("messages", messages);

  return (
    <div>
      {messages.map((message) => (
        <div key={message.id}>
          <div>{message.role === "user" ? "User: " : "AI: "}</div>
          <div>{message.content}</div>
          <div>
            {message.toolInvocations?.map((toolInvocation) => {
              const { toolName, toolCallId, state } = toolInvocation;

              if (state === "result") {
                if (toolName === "displayWeather") {
                  const { result } = toolInvocation;
                  return (
                    <div key={toolCallId}>
                      <Weather {...result} />
                    </div>
                  );
                }
              } else {
                return (
                  <div key={toolCallId}>
                    {toolName === "displayWeather" ? (
                      <div>Loading weather...</div>
                    ) : null}
                  </div>
                );
              }
            })}
          </div>
        </div>
      ))}
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="Type a message"
        ></input>
        <button type="submit">Send</button>
      </form>
    </div>
  );
};

export default ChatLiteUI;


```


## ğŸ“Œ Streaming Custom Data

>https://sdk.vercel.ai/docs/ai-sdk-ui/streaming-data#streaming-custom-data

íë¦„
- 1.createDataStreamResponse ì„ ë¦¬í„´í•˜ë©° executeì•ˆì—ì„œ streamTextê³¼ ë¨¸ì§€í•œë‹¤.  
- `result.mergeIntoDataStream(dataStream);`  
- 2.dataStream.writeData : ìŠ¤íŠ¸ë¦¼ ë°ì´í„°, useChatì˜ dataìœ¼ë¡œ ë„˜ì–´ì˜´  
- 3.dataStream.writeMessageAnnotation : ìŠ¤íŠ¸ë¦¼ ì–´ë…¸í…Œì´ì…˜ë°ì´í„°, ì£¼ì„ê³¼ ê°™ì€ ë©”íƒ€ì •ë³´ ë„£ëŠ”ê²ƒì´ ê°€ëŠ¥.  useChatì˜ message ê°ì²´ì™€ í•¨ê»˜ ë“¤ì–´ì˜´.  

```js
// app/api/chat-test/route.ts
import { openai } from "@ai-sdk/openai";
import { generateId, createDataStreamResponse, streamText } from "ai";

export async function POST(req: Request) {
  const { messages } = await req.json();

  // immediately start streaming (solves RAG issues with status, etc.)
  return createDataStreamResponse({
    execute: (dataStream) => {
      dataStream.writeData("initialized call");

      const result = streamText({
        model: openai("gpt-4o-mini"),
        messages,
        onChunk() {
          dataStream.writeMessageAnnotation({ chunk: "123" }); // annotation ì •ë³´ëŠ” messagesì•ˆì— í¬í•¨ë˜ë©° 
        },
        onFinish() {
          // message annotation:
          dataStream.writeMessageAnnotation({
            id: generateId(), // e.g. id from saved DB record
            other: "information",
          });

          // call annotation:
          dataStream.writeData("call completed");
        },
      });

      result.mergeIntoDataStream(dataStream);
    },
    onError: (error) => {
      // Error messages are masked by default for security reasons.
      // If you want to expose the error message to the client, you can do so here:
      return error instanceof Error ? error.message : String(error);
    },
  });
}

```

```js
"use client";

import { useChat } from "ai/react";

const ChatLiteUIStreamCustom = () => {
  const {
    messages,
    input,
    handleInputChange,
    handleSubmit,
    data: streamData,
  } = useChat({
    api: "/api/chat-test",
  });

  console.log("messages", messages);
  console.log("streamData", streamData);

  return (
    <div>
      {messages.map((message) => (
        <div key={message.id}>
          <div>{message.role === "user" ? "User: " : "AI: "}</div>
          <div id="content">{message.content}</div>
          <div id="annotations">
            {message.annotations && <>{JSON.stringify(message.annotations)}</>}
          </div>
        </div>
      ))}
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="Type a message"
        ></input>
        <button type="submit">Send</button>
      </form>
    </div>
  );
};

export default ChatLiteUIStreamCustom;

```

### eg) ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½í•˜ê¸°  
- streamText + useCompletion

```js
// api/router-hander.ts
export async function POST(request: NextRequest) {
  const body = await request.json(); // { prompt: string }

  const searchParams = request.nextUrl.searchParams;

  const videoId = searchParams.get("video_id");

  if (!videoId) {
    return NextResponse.json(
      { error: "ë¹„ë””ì˜¤ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤." },
      { status: 400 },
    );
  }

  const webhookData = await n8nService.getVideoInfo(videoId);

  const result = streamText({
    model: openai("gpt-4.1-nano"),
    system: "ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ìš”ì•½í•´ì¤˜",
    prompt: webhookData.text_only_ko,
  });

  return result.toDataStreamResponse();
}
---
// summary.tsx
import { Button } from "@/components/ui/button";
import { useCompletion } from "@ai-sdk/react";
import { Markdown } from "@/components/markdown/markdown";

const Summary = () => {
  const { completion, handleSubmit } = useCompletion({
    initialInput: "initial input", // body.prompt ê°’  
    initialCompletion: "initial completion", // ì´ˆê¸° LLM ì¶œë ¥ ë°ì´í„°  
    api: "http://localhost:3000/api/yt-summary/general-summary?video_id=s5FNl52TIpk",
    streamProtocol: "data", // streaming data protocol ì„ ë”°ë¥´ëŠ”ì§€ ì—¬ë¶€  
  });

  const onClickButton = () => {
    handleSubmit();
  };

  return (
    <div>
      <Button onClick={onClickButton}>Submit</Button>
      <Markdown>{completion}</Markdown>
    </div>
  );
};

export default Summary;

```

### eg) ë§ˆí¬ ë‹¤ìš´ ë¬¸ì„œ Streaming ì‘ë‹µ

- streamText + Streaming Custom Data  

```js
          const { fullStream } = await streamText({
            model: customModel(model.apiIdentifier),
            system:
              "Write about the given topic. Markdown is supported. Use headings wherever appropriate.",
            prompt: title,
          });

          for await (const delta of fullStream) {
            const { type } = delta;

            if (type === "text-delta") {
              const { textDelta } = delta;

              draftText += textDelta;
              streamingData.append({
                type: "text-delta",
                content: textDelta,
              });
            }
          }

          streamingData.append({ type: "finish", content: "" });
```

### eg) ë¬¸ì„œë¥¼ ì²¨ì‚­ Streaming Object  

- stream object + Streaming Custom Data

```js

          const { elementStream } = await streamObject({
            model: customModel(model.apiIdentifier),
            system:
              "You are a help writing assistant. Given a piece of writing, please offer suggestions to improve the piece of writing and describe the change. It is very important for the edits to contain full sentences instead of just words. Max 5 suggestions.",
            prompt: document.content,
            output: "array",
            schema: z.object({
              originalSentence: z.string().describe("The original sentence"),
              suggestedSentence: z.string().describe("The suggested sentence"),
              description: z
                .string()
                .describe("The description of the suggestion"),
            }),
          });

          for await (const element of elementStream) {
            const suggestion = {
              originalText: element.originalSentence,
              suggestedText: element.suggestedSentence,
              description: element.description,
              id: generateUUID(),
              documentId: documentId,
              isResolved: false,
            };

            streamingData.append({
              type: "suggestion",
              content: suggestion,
            });

            suggestions.push(suggestion);
          }
```