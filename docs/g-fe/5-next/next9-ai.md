---
sidebar_position: 9
---

# AI SDK  


## ðŸ“Œ Generative User Interfaces

íë¦„  
1.tools ì •ì˜ í•˜ê¸° - description, parameters, execute  
- ì˜ˆ, íŠ¹ì • ìœ„ì¹˜ì˜ ë‚ ì‹œë¥¼ ë³´ì—¬ì¤˜, ì¸ìžê°’:location, ì‹¤í–‰í•¨ìˆ˜ - ë‚ ì”¨ API  
2.Router Handlerì— streamText ìž‘ì„±í•˜ê¸°  
3.messages ì¤‘ toolInvocations í•„ë“œë¥¼ ë³´ê³  UIë¥¼ ëžœë”ë§ í•˜ê¸°  

ì œì•½
- gpt-4o-mini, gpt-4 ì´ìƒ ëª¨ë¸ ì„ íƒ  


```js
//lib/ai/tools.ts
import { tool as createTool } from "ai";
import { z } from "zod";

export const weatherTool = createTool({
  description: "Display the weather for a location",
  parameters: z.object({
    location: z.string(),
  }),
  execute: async function ({ location }) {
    await new Promise((resolve) => setTimeout(resolve, 2000));
    return { weather: "Sunny", temperature: 75, location };
  },
});

export const tools = {
  displayWeather: weatherTool,
};

---
// app/api/chat-test/route.ts
import { tools } from "@/lib/ai/tools";
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

export async function POST(request: Request) {
  const { messages } = await request.json();

  const result = streamText({
    model: openai("gpt-4o-mini"),
    system: "You are a friendly assistant!",
    messages,
    maxSteps: 5,
    tools,
  });

  return result.toDataStreamResponse();
}
```

```js
// components/chat-lite-ui
"use client";

import { useChat } from "ai/react";

type WeatherProps = {
  temperature: number;
  weather: string;
  location: string;
};

export const Weather = ({ temperature, weather, location }: WeatherProps) => {
  return (
    <div>
      <h2>Current Weather for {location}</h2>
      <p>Condition: {weather}</p>
      <p>Temperature: {temperature}Â°C</p>
    </div>
  );
};

const ChatLiteUI = () => {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: "/api/chat-test",
  });

  console.log("messages", messages);

  return (
    <div>
      {messages.map((message) => (
        <div key={message.id}>
          <div>{message.role === "user" ? "User: " : "AI: "}</div>
          <div>{message.content}</div>
          <div>
            {message.toolInvocations?.map((toolInvocation) => {
              const { toolName, toolCallId, state } = toolInvocation;

              if (state === "result") {
                if (toolName === "displayWeather") {
                  const { result } = toolInvocation;
                  return (
                    <div key={toolCallId}>
                      <Weather {...result} />
                    </div>
                  );
                }
              } else {
                return (
                  <div key={toolCallId}>
                    {toolName === "displayWeather" ? (
                      <div>Loading weather...</div>
                    ) : null}
                  </div>
                );
              }
            })}
          </div>
        </div>
      ))}
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="Type a message"
        ></input>
        <button type="submit">Send</button>
      </form>
    </div>
  );
};

export default ChatLiteUI;


```


## ðŸ“Œ Streaming Custom Data

>https://sdk.vercel.ai/docs/ai-sdk-ui/streaming-data#streaming-custom-data

íë¦„
- 1.createDataStreamResponse ì„ ë¦¬í„´í•˜ë©° executeì•ˆì—ì„œ streamTextê³¼ ë¨¸ì§€í•œë‹¤.  
- `result.mergeIntoDataStream(dataStream);`  
- 2.dataStream.writeData : ìŠ¤íŠ¸ë¦¼ ë°ì´í„°, useChatì˜ dataìœ¼ë¡œ ë„˜ì–´ì˜´  
- 3.dataStream.writeMessageAnnotation : ìŠ¤íŠ¸ë¦¼ ì–´ë…¸í…Œì´ì…˜ë°ì´í„°, ì£¼ì„ê³¼ ê°™ì€ ë©”íƒ€ì •ë³´ ë„£ëŠ”ê²ƒì´ ê°€ëŠ¥.  useChatì˜ message ê°ì²´ì™€ í•¨ê»˜ ë“¤ì–´ì˜´.  

```js
// app/api/chat-test/route.ts
import { openai } from "@ai-sdk/openai";
import { generateId, createDataStreamResponse, streamText } from "ai";

export async function POST(req: Request) {
  const { messages } = await req.json();

  // immediately start streaming (solves RAG issues with status, etc.)
  return createDataStreamResponse({
    execute: (dataStream) => {
      dataStream.writeData("initialized call");

      const result = streamText({
        model: openai("gpt-4o-mini"),
        messages,
        onChunk() {
          dataStream.writeMessageAnnotation({ chunk: "123" }); // annotation ì •ë³´ëŠ” messagesì•ˆì— í¬í•¨ë˜ë©° 
        },
        onFinish() {
          // message annotation:
          dataStream.writeMessageAnnotation({
            id: generateId(), // e.g. id from saved DB record
            other: "information",
          });

          // call annotation:
          dataStream.writeData("call completed");
        },
      });

      result.mergeIntoDataStream(dataStream);
    },
    onError: (error) => {
      // Error messages are masked by default for security reasons.
      // If you want to expose the error message to the client, you can do so here:
      return error instanceof Error ? error.message : String(error);
    },
  });
}

```

```js
"use client";

import { useChat } from "ai/react";

const ChatLiteUIStreamCustom = () => {
  const {
    messages,
    input,
    handleInputChange,
    handleSubmit,
    data: streamData,
  } = useChat({
    api: "/api/chat-test",
  });

  console.log("messages", messages);
  console.log("streamData", streamData);

  return (
    <div>
      {messages.map((message) => (
        <div key={message.id}>
          <div>{message.role === "user" ? "User: " : "AI: "}</div>
          <div id="content">{message.content}</div>
          <div id="annotations">
            {message.annotations && <>{JSON.stringify(message.annotations)}</>}
          </div>
        </div>
      ))}
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="Type a message"
        ></input>
        <button type="submit">Send</button>
      </form>
    </div>
  );
};

export default ChatLiteUIStreamCustom;

```