"use strict";(self.webpackChunkdosimpact_blog=self.webpackChunkdosimpact_blog||[]).push([[86641],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>k});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),p=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=p(e.components);return r.createElement(s.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(n),d=a,k=u["".concat(s,".").concat(d)]||u[d]||m[d]||o;return n?r.createElement(k,i(i({ref:t},c),{},{components:n})):r.createElement(k,i({ref:t},c))}));function k(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:a,i[1]=l;for(var p=2;p<o;p++)i[p]=n[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},7442:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var r=n(87462),a=(n(67294),n(3905));const o={sidebar_position:1},i="NVIDIA Triton Inference Server Intro",l={unversionedId:"g-devops/triton/triton-01",id:"g-devops/triton/triton-01",title:"NVIDIA Triton Inference Server Intro",description:"- NVIDIA Triton Inference Server Intro",source:"@site/docs/g-devops/8-triton/triton-01.md",sourceDirName:"g-devops/8-triton",slug:"/g-devops/triton/triton-01",permalink:"/docs/g-devops/triton/triton-01",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/g-devops/8-triton/triton-01.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"devOps",previous:{title:"8.Triton",permalink:"/docs/category/8triton"},next:{title:"gRPC \uac1c\ub150 \uc815\ub9bd",permalink:"/docs/g-devops/triton/triton-02"}},s={},p=[{value:"1. \uc8fc\uc694 \ud2b9\uc9d5 \ubc0f \uc7a5\uc810",id:"1-\uc8fc\uc694-\ud2b9\uc9d5-\ubc0f-\uc7a5\uc810",level:3},{value:"2. Triton\uc758 \ud575\uc2ec \uc544\ud0a4\ud14d\ucc98",id:"2-triton\uc758-\ud575\uc2ec-\uc544\ud0a4\ud14d\ucc98",level:3},{value:"3. Quick Start",id:"3-quick-start",level:3},{value:"4. \uc815\ub9ac",id:"4-\uc815\ub9ac",level:3}],c={toc:p},u="wrapper";function m(e){let{components:t,...o}=e;return(0,a.kt)(u,(0,r.Z)({},c,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"nvidia-triton-inference-server-intro"},"NVIDIA Triton Inference Server Intro"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#nvidia-triton-inference-server-intro"},"NVIDIA Triton Inference Server Intro"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#1-%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95-%EB%B0%8F-%EC%9E%A5%EC%A0%90"},"1. \uc8fc\uc694 \ud2b9\uc9d5 \ubc0f \uc7a5\uc810")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#2-triton%EC%9D%98-%ED%95%B5%EC%8B%AC-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98"},"2. Triton\uc758 \ud575\uc2ec \uc544\ud0a4\ud14d\ucc98")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#3-quick-start"},"3. Quick Start")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#4-%EC%A0%95%EB%A6%AC"},"4. \uc815\ub9ac"))))),(0,a.kt)("p",null,"NVIDIA Triton Inference Server (\uc774\ud558 Triton)\ub294 NVIDIA\uc5d0\uc11c \uac1c\ubc1c\ud55c ",(0,a.kt)("strong",{parentName:"p"},"\uc624\ud508 \uc18c\uc2a4 AI \ubaa8\ub378 \ucd94\ub860 \uc804\uc6a9 \uc11c\ubc84 \uc18c\ud504\ud2b8\uc6e8\uc5b4"),"  "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\uac04\ub2e8\ud788 \ub9d0\ud574, \ud559\uc2b5\uc774 \uc644\ub8cc\ub41c AI \ubaa8\ub378\uc744 \uc2e4\uc81c \uc11c\ube44\uc2a4(\uc6b4\uc601 \ud658\uacbd)\uc5d0 \uc27d\uac8c \ubc30\ud3ec \ud574\uc8fc\uace0, \ud074\ub77c\uc774\uc5b8\ud2b8\uc758 \uc694\uccad\uc5d0 \ub530\ub77c \uacb0\uacfc\ub97c \ucd9c\ub825(\ucd94\ub860)\ud574\uc8fc\ub294 \uc5ed\ud560  "),(0,a.kt)("li",{parentName:"ul"},"\ud2b9\uc815 \ud504\ub808\uc784\uc6cc\ud06c\ub098 \ud558\ub4dc\uc6e8\uc5b4\uc5d0 \uc885\uc18d\ub418\uc9c0 \uc54a\uace0 \ubc94\uc6a9\uc801\uc73c\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc774 \uac00\uc7a5 \ud070 \ud2b9\uc9d5   "),(0,a.kt)("li",{parentName:"ul"},"*\ucd94\ub860(Inference) : \ud559\uc2b5\ub41c \ubaa8\ub378\uc774 \uc2e4\uc81c \ub370\uc774\ud130\ub97c \uc785\ub825\ubc1b\uc544 \uacb0\uacfc\ub97c \ub0b4\ub193\ub294 \uacfc\uc815    ")),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Alt text",src:n(72351).Z,width:"2562",height:"1238"})),(0,a.kt)("h3",{id:"1-\uc8fc\uc694-\ud2b9\uc9d5-\ubc0f-\uc7a5\uc810"},"1. \uc8fc\uc694 \ud2b9\uc9d5 \ubc0f \uc7a5\uc810"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\ub2e4\uc591\ud55c \ud504\ub808\uc784\uc6cc\ud06c \uc9c0\uc6d0 (Framework Agnostic): PyTorch, TensorFlow, ONNX, TensorRT, OpenVINO\ub294 \ubb3c\ub860 Python \uae30\ubc18\uc758 \ucee4\uc2a4\ud140 \ucf54\ub4dc(Scikit-learn \ub4f1)\uae4c\uc9c0 \ud55c \uc11c\ubc84\uc5d0\uc11c \ub3d9\uc2dc\uc5d0 \ub3cc\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"\uace0\uc131\ub2a5 \ucd5c\uc801\ud654"),":",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"\ub2e4\uc774\ub098\ubbf9 \ubc30\uce6d(Dynamic Batching)"),": \uc5ec\ub7ec \ud074\ub77c\uc774\uc5b8\ud2b8\uc758 \uac1c\ubcc4 \uc694\uccad\uc744 \uc11c\ubc84\uc5d0\uc11c \uc790\ub3d9\uc73c\ub85c \ubb36\uc5b4 \ucc98\ub9ac\ud568\uc73c\ub85c\uc368 GPU/CPU \ud65c\uc6a9\ub3c4\ub97c \uadf9\ub300\ud654\ud558\uace0 \ucc98\ub9ac\ub7c9\uc744 \ub298\ub9bd\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"\ubcd1\ub82c \ubaa8\ub378 \uc2e4\ud589 (Concurrent Model Execution)"),": \ud558\ub098\uc758 GPU\uc5d0\uc11c \uc5ec\ub7ec \ubaa8\ub378\uc744 \ub3d9\uc2dc\uc5d0 \uc2e4\ud589\ud558\uac70\ub098, \ub3d9\uc77c \ubaa8\ub378\uc758 \uc778\uc2a4\ud134\uc2a4\ub97c \uc5ec\ub7ec \uac1c \ub744\uc6cc \uc131\ub2a5\uc744 \ub192\uc785\ub2c8\ub2e4."))),(0,a.kt)("li",{parentName:"ul"},"NVIDIA GPU\ubfd0\ub9cc \uc544\ub2c8\ub77c x86/ARM CPU \ud658\uacbd\uc5d0\uc11c\ub3c4 \ub3d9\uc791\ud558\uba70, \ud074\ub77c\uc6b0\ub4dc(AWS, GCP, Azure), \uc628\ud504\ub808\ubbf8\uc2a4, \uc5e3\uc9c0 \uae30\uae30\uae4c\uc9c0 \ubc30\ud3ec\uac00 \uac00\ub2a5\ud569\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ul"},"HTTP/REST \ubc0f gRPC \ud504\ub85c\ud1a0\ucf5c\uc744 \uc9c0\uc6d0\ud558\uba70, Kubernetes(KServe, Kubeflow)\uc640 \uc27d\uac8c \ud1b5\ud569\ub429\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ul"},"\uc11c\ubc84 \uc7ac\uc2dc\uc791 \uc5c6\uc774 \ubaa8\ub378\uc744 \uc2e4\uc2dc\uac04\uc73c\ub85c \ub85c\ub4dc/\uc5b8\ub85c\ub4dc\ud558\uac70\ub098 \ubc84\uc804\uc744 \uad00\ub9ac(A/B \ud14c\uc2a4\ud2b8 \ub4f1)\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  "),(0,a.kt)("li",{parentName:"ul"},"Docker file \uc9c0\uc6d0\uc73c\ub85c CI/CD \ud30c\uc774\ud504\ub77c\uc778 \uacb0\ud569 \uc6a9\uc774.  ")),(0,a.kt)("hr",null),(0,a.kt)("h3",{id:"2-triton\uc758-\ud575\uc2ec-\uc544\ud0a4\ud14d\ucc98"},"2. Triton\uc758 \ud575\uc2ec \uc544\ud0a4\ud14d\ucc98"),(0,a.kt)("p",null,"Triton\uc740 \ud06c\uac8c \uc138 \uac00\uc9c0 \uc601\uc5ed\uc73c\ub85c \ub098\ub269\ub2c8\ub2e4."),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Model Repository"),": \uc11c\ubc84\uac00 \uc2e4\ud589\ub420 \ub54c \uc77d\uc5b4\uc62c \ubaa8\ub378 \ud30c\uc77c\uacfc \uc124\uc815\uac12(",(0,a.kt)("inlineCode",{parentName:"li"},"config.pbtxt"),")\uc774 \uc800\uc7a5\ub41c \ub514\ub809\ud1a0\ub9ac\uc785\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Server Core"),": \ud074\ub77c\uc774\uc5b8\ud2b8 \uc694\uccad\uc744 \ubc1b\uace0, \uc801\uc808\ud55c \ubaa8\ub378 \uc2a4\ucf00\uc904\ub7ec(Stateless, Stateful, Ensemble \ub4f1)\ub85c \uc804\ub2ec\ud558\ub294 \ud575\uc2ec \uc5d4\uc9c4\uc785\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Backends"),": \uc2e4\uc81c \ubaa8\ub378\uc744 \uad6c\ub3d9\ud558\ub294 \uc5d4\uc9c4(PyTorch, TensorFlow \ub4f1)\uc73c\ub85c, \ucf54\uc5b4\uc640 \ubd84\ub9ac\ub418\uc5b4 \uc788\uc5b4 \ud655\uc7a5\uc774 \uc27d\uc2b5\ub2c8\ub2e4.")),(0,a.kt)("p",null,"Q,Triton\uc740 Apple Chip\uc758 \ub274\ub7f4\uc5d4\uc9c4\uc744 \uc0ac\uc6a9\ud558\ub294\uac00?  "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\uc544\ub2c8\ub2e4, Triton\uc740 \uc774\ub984\uc5d0\uc11c \uc54c \uc218 \uc788\ub4ef\uc774 NVIDIA GPU(CUDA) \ud658\uacbd\uc5d0 \ucd5c\uc801\ud654\ub41c \uc11c\ubc84.  "),(0,a.kt)("li",{parentName:"ul"},"\ub274\ub7f4 \uc5d4\uc9c4\uc740 Core ML\uc774\ub77c\ub294 \uc560\ud50c \uc804\uc6a9 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud1b5\ud574 \ucd5c\uc801\ud654\ub418\uc5c8\uc744 \ub54c \uac00\uc7a5 \uac15\ub825.  "),(0,a.kt)("li",{parentName:"ul"},"Triton\uc740 \uc774\ub97c \uc9c0\uc6d0\ud558\uc9c0 \uc54a\ub294\ub2e4.  ")),(0,a.kt)("h3",{id:"3-quick-start"},"3. Quick Start"),(0,a.kt)("p",null,"Reference Docker Version  : ",(0,a.kt)("a",{parentName:"p",href:"https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel-25-12.html#rel-25-12"},"https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel-25-12.html#rel-25-12")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'# \ub514\ub809\ud130\ub9ac \uc774\ub3d9 \ncd Quick_Start\n# \uc608\uc81c \ubaa8\ub378 \ub2e4\uc6b4\ub85c\ub4dc  \nfetch_models.sh\n# \uc774\ubbf8\uc9c0 \ub2e4\uc6b4\ub85c\ub4dc  \ndocker pull nvcr.io/nvidia/tritonserver:25.12-py3\n# docker container up \ndocker run --rm \\\n  -p 8000:8000 -p 8001:8001 -p 8002:8002 \\\n  -v ./model_repository:/models \\\n  nvcr.io/nvidia/tritonserver:25.12-py3 \\\n  tritonserver --model-repository=/models\n\n# Check Logs\nI0122 12:01:38.001149 1 grpc_server.cc:2562] "Started GRPCInferenceService at 0.0.0.0:8001"\nI0122 12:01:38.001294 1 http_server.cc:4815] "Started HTTPService at 0.0.0.0:8000"\nI0122 12:01:38.055684 1 http_server.cc:358] "Started Metrics Service at 0.0.0.0:8002"\n\n# Check health check\ncurl -v localhost:8000/v2/health/ready\n* Host localhost:8000 was resolved.\n* IPv6: ::1\n* IPv4: 127.0.0.1\n*   Trying [::1]:8000...\n* Connected to localhost (::1) port 8000\n> GET /v2/health/ready HTTP/1.1\n> Host: localhost:8000\n> User-Agent: curl/8.7.1\n> Accept: */*\n> \n* Request completely sent off\n< HTTP/1.1 200 OK\n< Content-Length: 0\n< Content-Type: text/plain\n< \n* Connection #0 to host localhost left intact\n\n---\n\n # densenet_onnx \ubaa8\ub378\uc758 \uc785\ub825/\ucd9c\ub825 \uad6c\uc870 \ud655\uc778\ncurl localhost:8000/v2/models/densenet_onnx/config\n\n{"name":"densenet_onnx","platform":"onnxruntime_onnx","backend":"onnxruntime","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"data_0","data_type":"TYPE_FP32","format":"FORMAT_NONE","dims":[1,3,224,224],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"fc6_1","data_type":"TYPE_FP32","dims":[1,1000,1,1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"instance_group":[{"name":"densenet_onnx","kind":"KIND_CPU","count":2,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.onnx","cc_model_filenames":{},"metric_tags":{},"parameters":{},"model_warmup":[]}%                                    \n')),(0,a.kt)("h3",{id:"4-\uc815\ub9ac"},"4. \uc815\ub9ac"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Alt text",src:n(72351).Z,width:"2562",height:"1238"})),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\ucd94\ub860 \uc694\uccad\uc740 gRPC, HTTP \ub610\ub294 C API\ub97c \ud1b5\ud574 Triton\uc73c\ub85c \ubcf4\ub0bc \uc218 \uc788\uc73c\uba70, \uae30\ubcf8\uc801\uc73c\ub85c \uc21c\ucc28\uc801\uc73c\ub85c \ucc98\ub9ac\ub418\uc9c0\ub9cc \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc704\ud574 \uc77c\uad04 \ucc98\ub9ac\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ul"},"\uac01 \ubaa8\ub378\uc740 \ucd94\ub860 \uc694\uccad \ub300\uae30\uc5f4\uc744 \uad00\ub9ac\ud558\ub294 \uc790\uccb4 \uc2a4\ucf00\uc904\ub7ec\ub97c \uac00\uc9d1\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ul"},"\ubaa8\ub378\uc740 \uc11c\ubc84 \uc7ac\uc2dc\uc791 \uc5c6\uc774 \ud074\ub77c\uc6b0\ub4dc \uc2a4\ud1a0\ub9ac\uc9c0 \ub610\ub294 \ub85c\uceec \ud30c\uc77c \uc2dc\uc2a4\ud15c\uc5d0\uc11c \ub3d9\uc801\uc73c\ub85c \ub85c\ub4dc\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4."),(0,a.kt)("li",{parentName:"ul"},"\uc2a4\ucf00\uc904\ub7ec\ub294 \uc694\uccad\uc744 \uc801\uc808\ud55c \ud504\ub808\uc784\uc6cc\ud06c \ubc31\uc5d4\ub4dc\ub85c \ubcf4\ub0b4 \uc2e4\uc81c \uacc4\uc0b0\uc744 \uc218\ud589\ud558\uace0, \ucd9c\ub825 \ud150\uc11c\ub294 \ud074\ub77c\uc774\uc5b8\ud2b8\ub85c \ub2e4\uc2dc \uc804\uc1a1\ub429\ub2c8\ub2e4.  "),(0,a.kt)("li",{parentName:"ul"},"\uace0\uae09 \uae30\ub2a5 : Dynamic Batching, Launches tow instances per GPU, TensorRT EP acceleration on ONNX Runtime backend, Ensemble of model  "),(0,a.kt)("li",{parentName:"ul"},"Model Analyzer  : ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/triton-inference-server/model_analyzer"},"https://github.com/triton-inference-server/model_analyzer"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Triton Model Analyzer\ub294 Triton \ucd94\ub860 \uc11c\ubc84 \uc5d0\uc11c \uc2e4\ud589\ub418\ub294 \ub2e8\uc77c, \ub2e4\uc911, \uc559\uc0c1\ube14 \ub610\ub294 BLS \ubaa8\ub378\uc5d0 \ub300\ud574 \ud2b9\uc815 \ud558\ub4dc\uc6e8\uc5b4 \ud658\uacbd\uc5d0\uc11c \ucd5c\uc801\uc758 \uad6c\uc131\uc744 \ucc3e\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc8fc\ub294 CLI \ub3c4\uad6c\uc785\ub2c8\ub2e4 . Model Analyzer\ub294 \ub610\ud55c \ub2e4\uc591\ud55c \uad6c\uc131\uc758 \uc7a5\ub2e8\uc810\uacfc \uac01 \uad6c\uc131\uc5d0 \ud544\uc694\ud55c \ucef4\ud4e8\ud305 \ubc0f \uba54\ubaa8\ub9ac \uc694\uad6c \uc0ac\ud56d\uc744 \ub354 \uc798 \uc774\ud574\ud560 \uc218 \uc788\ub3c4\ub85d \ubcf4\uace0\uc11c\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4."))),(0,a.kt)("li",{parentName:"ul"},"Model Navigator : ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/orgs/triton-inference-server/repositories?q=navigator"},"https://github.com/orgs/triton-inference-server/repositories?q=navigator"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Triton Model Navigator\ub294 PyTorch, TensorFlow \ub610\ub294 ONNX\ub85c \uad6c\ud604\ub41c \ubaa8\ub378 \ubc0f \ud30c\uc774\ud504\ub77c\uc778\uc744 TensorRT\ub85c \uc804\ud658\ud558\ub294 \uacfc\uc815\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \uac04\uc18c\ud654.",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"TensorRT: NVIDIA\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uace0\uc131\ub2a5 \ub525\ub7ec\ub2dd \ucd94\ub860 \ucd5c\uc801\ud654 \uc5d4\uc9c4\uc785\ub2c8\ub2e4. PyTorch\ub098 TensorFlow \ubaa8\ub378\uc744 \uc774 \ud615\uc2dd\uc73c\ub85c \ubcc0\ud658\ud558\uba74 GPU\uc5d0\uc11c \ud6e8\uc52c \ube60\ub974\uac8c \uc791\ub3d9\ud569\ub2c8\ub2e4."))),(0,a.kt)("li",{parentName:"ul"},"TensorFlow \uc5d0\uc11c Tensor\uc758 \uc758\ubbf8? \ub2e4\ucc28\uc6d0 \ubc30\uc5f4(Multi-dimensional Array) \ub370\uc774\ud130\ub97c \ub2f4\ub294 \ucee8\ud14c\uc774\ub108, GPU\ub77c\ub294 \ud558\ub4dc\uc6e8\uc5b4\uac00 \ub370\uc774\ud130\ub97c \ucc98\ub9ac\ud558\ub294 \ubb3c\ub9ac\uc801\uc778 \ubc29\uc2dd\uacfc \uc644\ubcbd\ud558\uac8c \ub9de\ubb3c\ub824 \uc788\uc74c.  ")))))),(0,a.kt)("p",null,"Ref "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://velog.io/@mmodestaa/%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8-%EC%84%9C%EB%B9%99-%EC%8B%9C-%EC%95%8C%EB%A9%B4-%EC%A2%8B%EC%9D%80-%EA%B0%9C%EB%85%90%EB%93%A4-Triton-Inference-Server-HTTP-Rest-API-gRPC"},"https://velog.io/@mmodestaa/%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8-%EC%84%9C%EB%B9%99-%EC%8B%9C-%EC%95%8C%EB%A9%B4-%EC%A2%8B%EC%9D%80-%EA%B0%9C%EB%85%90%EB%93%A4-Triton-Inference-Server-HTTP-Rest-API-gRPC"))))}m.isMDXComponent=!0},72351:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/image-ac71f7b3f4dcdb2afac00d7d9d34bf22.png"}}]);