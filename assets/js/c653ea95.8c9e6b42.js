"use strict";(self.webpackChunkdosimpact_blog=self.webpackChunkdosimpact_blog||[]).push([[32640],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>g});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),m=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},p=function(e){var t=m(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=m(n),d=r,g=u["".concat(l,".").concat(d)]||u[d]||c[d]||o;return n?a.createElement(g,s(s({ref:t},p),{},{components:n})):a.createElement(g,s({ref:t},p))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,s=new Array(o);s[0]=d;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[u]="string"==typeof e?e:r,s[1]=i;for(var m=2;m<o;m++)s[m]=n[m];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},14780:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>i,toc:()=>m});var a=n(87462),r=(n(67294),n(3905));const o={sidebar_position:20},s="20, AI SDK",i={unversionedId:"g-hard/llm/7-2-llm-app/llm-20-next-ai-sdk-1",id:"g-hard/llm/7-2-llm-app/llm-20-next-ai-sdk-1",title:"20, AI SDK",description:"- 20, AI SDK",source:"@site/docs/g-hard/7-llm/7-2-llm-app/llm-20-next-ai-sdk-1.md",sourceDirName:"g-hard/7-llm/7-2-llm-app",slug:"/g-hard/llm/7-2-llm-app/llm-20-next-ai-sdk-1",permalink:"/docs/g-hard/llm/7-2-llm-app/llm-20-next-ai-sdk-1",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/g-hard/7-llm/7-2-llm-app/llm-20-next-ai-sdk-1.md",tags:[],version:"current",sidebarPosition:20,frontMatter:{sidebar_position:20},sidebar:"hardSkill",previous:{title:"SSE to NDJSON",permalink:"/docs/g-hard/llm/7-2-llm-app/llm-21-next-sse"}},l={},m=[{value:"\uc8fc\uc694 \ud568\uc218\ub4e4",id:"\uc8fc\uc694-\ud568\uc218\ub4e4",level:2},{value:"Stream Protocols",id:"stream-protocols",level:2},{value:"\ud83d\udccc Basic",id:"-basic",level:2},{value:"\ud83d\udccc Generative User Interfaces",id:"-generative-user-interfaces",level:2},{value:"\ud83d\udccc Streaming Custom Data",id:"-streaming-custom-data",level:2},{value:"eg) \uc2a4\ud06c\ub9bd\ud2b8 \uc694\uc57d\ud558\uae30",id:"eg-\uc2a4\ud06c\ub9bd\ud2b8-\uc694\uc57d\ud558\uae30",level:3},{value:"eg) \ub9c8\ud06c \ub2e4\uc6b4 \ubb38\uc11c Streaming \uc751\ub2f5",id:"eg-\ub9c8\ud06c-\ub2e4\uc6b4-\ubb38\uc11c-streaming-\uc751\ub2f5",level:3},{value:"eg) \ubb38\uc11c\ub97c \ucca8\uc0ad Streaming Object",id:"eg-\ubb38\uc11c\ub97c-\ucca8\uc0ad-streaming-object",level:3}],p={toc:m},u="wrapper";function c(e){let{components:t,...n}=e;return(0,r.kt)(u,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"20-ai-sdk"},"20, AI SDK"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#20-ai-sdk"},"20, AI SDK"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#%EC%A3%BC%EC%9A%94-%ED%95%A8%EC%88%98%EB%93%A4"},"\uc8fc\uc694 \ud568\uc218\ub4e4")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#stream-protocols"},"Stream Protocols")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#-basic"},"\ud83d\udccc Basic")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#-generative-user-interfaces"},"\ud83d\udccc Generative User Interfaces")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#-streaming-custom-data"},"\ud83d\udccc Streaming Custom Data"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#eg-%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8-%EC%9A%94%EC%95%BD%ED%95%98%EA%B8%B0"},"eg) \uc2a4\ud06c\ub9bd\ud2b8 \uc694\uc57d\ud558\uae30")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#eg-%EB%A7%88%ED%81%AC-%EB%8B%A4%EC%9A%B4-%EB%AC%B8%EC%84%9C-streaming-%EC%9D%91%EB%8B%B5"},"eg) \ub9c8\ud06c \ub2e4\uc6b4 \ubb38\uc11c Streaming \uc751\ub2f5")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#eg-%EB%AC%B8%EC%84%9C%EB%A5%BC-%EC%B2%A8%EC%82%AD-streaming-object"},"eg) \ubb38\uc11c\ub97c \ucca8\uc0ad Streaming Object"))))))),(0,r.kt)("h2",{id:"\uc8fc\uc694-\ud568\uc218\ub4e4"},"\uc8fc\uc694 \ud568\uc218\ub4e4"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Blocking UI vs Streaming UI : ",(0,r.kt)("a",{parentName:"p",href:"https://sdk.vercel.ai/docs/foundations/streaming"},"https://sdk.vercel.ai/docs/foundations/streaming"),"  ")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"generateText : Blocking UI + text"),(0,r.kt)("li",{parentName:"ul"},"generateObject : Blocking UI + object  ",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://sdk.vercel.ai/docs/advanced/sequential-generations"},"https://sdk.vercel.ai/docs/advanced/sequential-generations"),"  "))),(0,r.kt)("li",{parentName:"ul"},"streamObject : Streaming UI + text"),(0,r.kt)("li",{parentName:"ul"},"streamText : Streaming UI + object"),(0,r.kt)("li",{parentName:"ul"},"createDataStreamResponse : Streaming UI + Streaming Custom Data  ")),(0,r.kt)("h2",{id:"stream-protocols"},"Stream Protocols"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("a",{parentName:"p",href:"https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol"},"https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol"),"  ")),(0,r.kt)("p",null,"stream protocol \uc774\ub780?  "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"HTTP \ud504\ub85c\ud1a0\ucf5c \uc704\uc5d0\uc11c \uc2a4\ud2b8\ub9bc \ub370\uc774\ud130\ub97c \ub118\uae30\ub294 \uaddc\uce59. ( text stream, data stream \ubaa8\ub450 \ud3ec\ud568 )  ")),(0,r.kt)("p",null,"Text Stream Protocol"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"streamText().toTextStreamResponse();"),"   \uc0ac\uc6a9  ")),(0,r.kt)("p",null,"Data Stream Protocol"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"createDataStreamResponse")," \uc0ac\uc6a9    ")),(0,r.kt)("p",null,"*\ud0c0\uc785 \uad6c\ubd84\uc744 \ud1b5\ud574\uc11c Stream Protocol \ub0b4 Text, Data \ubaa8\ub450 \ub0b4\ub824\uc62c \uc218 \uc788\ub2e4.   "),(0,r.kt)("p",null,"*TypeID = 0,  Text Part  "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Format: 0:string\\n  ")),(0,r.kt)("p",null,"*TypeID = 2,  Data Part  "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Format: 2:",'[{"key":"object1"},{"anotherKey":"object2"}]',"\\n  ")),(0,r.kt)("p",null,"*TypeID = 8,  Message Annotation Part  "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Format: 8:",'[{"id":"message-123","other":"annotation"}]',"\\n   ")),(0,r.kt)("p",null,"*TypeID = 3,  Error Part"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},'Format: 3:"error message"\\n    ')),(0,r.kt)("p",null,"*TypeID = 3,  Tool Call Streaming Start Part"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},'Format: b:{"toolCallId":"call-456","toolName":"streaming-tool"}\\n',(0,r.kt)("br",{parentName:"li"}),"*TypeID = c,  Tool Call Delta Part"),(0,r.kt)("li",{parentName:"ul"},'Format: c:{"toolCallId":"call-456","argsTextDelta":"partial arg"}\\n\n*TypeID = 9,  Tool Call Part'),(0,r.kt)("li",{parentName:"ul"},'Format: 9:{"toolCallId":"call-123","toolName":"my-tool","args":{"some":"argument"}}\\n\n*TypeID = a,  Tool Result Part'),(0,r.kt)("li",{parentName:"ul"},'Format: a:{"toolCallId":"call-123","result":"tool output"}\\n')),(0,r.kt)("p",null,"*TypeID = e,  Finish Step Part"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},'Format: e:{"finishReason":"stop","usage":{"promptTokens":10,"completionTokens":20},"isContinued":false}\\n\n*TypeID = d,  Finish Message Part'),(0,r.kt)("li",{parentName:"ul"},'Format: d:{"finishReason":"stop","usage":{"promptTokens":10,"completionTokens":20}}\\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'// \uc751\ub2f5 \uc608 \n// TypeID, Type delimiter(:), Text|Data Chunk, Chunk delimiter 4\uac00\uc9c0 \ud30c\ud2b8\ub85c \uad6c\uc131  \n\n2:["initialized call"]\n8:[{"chunk":"123"}]\n0:"Hello"\n8:[{"chunk":"123"}]\n0:"!"\n8:[{"chunk":"123"}]\n0:" How"\n8:[{"chunk":"123"}]\n0:" can"\n8:[{"chunk":"123"}]\n0:" I"\n8:[{"chunk":"123"}]\n0:" assist"\n8:[{"chunk":"123"}]\n0:" you"\n8:[{"chunk":"123"}]\n0:" today"\n8:[{"chunk":"123"}]\n0:"?"\n8:[{"id":"DU5YpIiiuczDZpiN","other":"information"}]\n2:["call completed"]\ne:{"finishReason":"stop","usage":{"promptTokens":8,"completionTokens":9},"isContinued":false}\nd:{"finishReason":"stop","usage":{"promptTokens":8,"completionTokens":9}}\n')),(0,r.kt)("h2",{id:"-basic"},"\ud83d\udccc Basic"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'// app/api/chat-test/route.ts\nimport { openai } from "@ai-sdk/openai";\nimport { streamText } from "ai";\n\nexport async function POST(request: Request) {\n  const { messages } = await request.json();\n\n  const result = streamText({\n    model: openai("gpt-4o-mini"),\n    system: "You are a friendly assistant!",\n    messages,\n    maxSteps: 5,\n  });\n\n  return result.toDataStreamResponse();\n}\n---\n// chat-lite.tsx\n"use client";\n\nimport { generateUUID } from "@/lib/utils";\nimport { useChat } from "ai/react";\nimport React from "react";\n\n/*\n[\n    {\n        "role": "user",\n        "content": "my name is jay",\n        "id": "bPclYKo27gxhIoWn",\n        "createdAt": "2024-12-12T12:28:11.371Z"\n    },\n    {\n        "id": "NPFi3J8vWw7Sa5uw", \n        "role": "assistant",\n        "content": "Nice to meet you, Jay! How can I assist you today?",\n        "createdAt": "2024-12-12T12:28:13.252Z",\n        "revisionId": "pDmdPLtSHFUvn3Bi"\n    }\n]*/\n\nconst ChatLite = ({ id }: { id: string }) => {\n  const {\n    messages, // \uc9c0\uae08\uae4c\uc9c0\uc758 \ub204\uc801 \uba54\uc2dc\uc9c0 \ub9ac\uc2a4\ud2b8\n    setMessages, // \uba54\uc2dc\uc9c0 setter, (api call \uc5c6\uc74c)\n    input, // \uc0ac\uc6a9\uc790 \uc785\ub825 & setter\n    setInput,\n    handleSubmit, // input\uc758 \ub0b4\uc6a9\uc744 \ubaa8\ub378\uc5d0 \uc804\uc1a1, message\uac1d\uccb4 \ucd94\uac00, input \ucd08\uae30\ud654\n    append, // \uc0ac\uc6a9\uc790 message \ucd94\uac00 \ud6c4 \ubc14\ub85c api \ud638\ucd9c.\n    isLoading,\n    stop, // abort the current API\n    data: streamingData, //\ucd5c\uadfc \uc751\ub2f5\ub370\uc774\ud130\uc758 \uc2a4\ud2b8\ub9bc\n  } = useChat({\n    api: "/api/chat",\n    body: { id: id, modelId: "gpt-4o-mini" },\n  });\n\n  // send continue message\n  console.log({ id, messages, streamingData });\n\n  return (\n    <div>\n      <div>{JSON.stringify(messages)}</div>\n      <input value={input} onChange={(e) => setInput(e.target.value)} />\n      <button onClick={handleSubmit}>send</button>\n      {/* append */}\n      <div>\n        <button\n          onClick={() => append({ role: "user", content: "my name is jay" })}\n        >\n          Append suggested message!\n        </button>\n      </div>\n    </div>\n  );\n};\n\nexport default ChatLite;\n')),(0,r.kt)("h2",{id:"-generative-user-interfaces"},"\ud83d\udccc Generative User Interfaces"),(0,r.kt)("p",null,"\ud750\ub984  "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"1.tools \uc815\uc758 \ud558\uae30 - description, parameters, execute    ",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\uc608, \ud2b9\uc815 \uc704\uce58\uc758 \ub0a0\uc2dc\ub97c \ubcf4\uc5ec\uc918, \uc778\uc790\uac12:location, \uc2e4\ud589\ud568\uc218 - \ub0a0\uc528 API    "))),(0,r.kt)("li",{parentName:"ul"},"2.Router Handler\uc5d0 streamText \uc791\uc131\ud558\uae30    "),(0,r.kt)("li",{parentName:"ul"},"3.messages \uc911 toolInvocations \ud544\ub4dc\ub97c \ubcf4\uace0 UI\ub97c \ub79c\ub354\ub9c1 \ud558\uae30    ")),(0,r.kt)("p",null,"\uc81c\uc57d"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"gpt-4o-mini, gpt-4 \uc774\uc0c1 \ubaa8\ub378 \uc120\ud0dd  ")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'//lib/ai/tools.ts\nimport { tool as createTool } from "ai";\nimport { z } from "zod";\n\nexport const weatherTool = createTool({\n  description: "Display the weather for a location",\n  parameters: z.object({\n    location: z.string(),\n  }),\n  execute: async function ({ location }) {\n    await new Promise((resolve) => setTimeout(resolve, 2000));\n    return { weather: "Sunny", temperature: 75, location };\n  },\n});\n\nexport const tools = {\n  displayWeather: weatherTool,\n};\n\n---\n// app/api/chat-test/route.ts\nimport { tools } from "@/lib/ai/tools";\nimport { openai } from "@ai-sdk/openai";\nimport { streamText } from "ai";\n\nexport async function POST(request: Request) {\n  const { messages } = await request.json();\n\n  const result = streamText({\n    model: openai("gpt-4o-mini"),\n    system: "You are a friendly assistant!",\n    messages,\n    maxSteps: 5,\n    tools,\n  });\n\n  return result.toDataStreamResponse();\n}\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'// components/chat-lite-ui\n"use client";\n\nimport { useChat } from "ai/react";\n\ntype WeatherProps = {\n  temperature: number;\n  weather: string;\n  location: string;\n};\n\nexport const Weather = ({ temperature, weather, location }: WeatherProps) => {\n  return (\n    <div>\n      <h2>Current Weather for {location}</h2>\n      <p>Condition: {weather}</p>\n      <p>Temperature: {temperature}\xb0C</p>\n    </div>\n  );\n};\n\nconst ChatLiteUI = () => {\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    api: "/api/chat-test",\n  });\n\n  console.log("messages", messages);\n\n  return (\n    <div>\n      {messages.map((message) => (\n        <div key={message.id}>\n          <div>{message.role === "user" ? "User: " : "AI: "}</div>\n          <div>{message.content}</div>\n          <div>\n            {message.toolInvocations?.map((toolInvocation) => {\n              const { toolName, toolCallId, state } = toolInvocation;\n\n              if (state === "result") {\n                if (toolName === "displayWeather") {\n                  const { result } = toolInvocation;\n                  return (\n                    <div key={toolCallId}>\n                      <Weather {...result} />\n                    </div>\n                  );\n                }\n              } else {\n                return (\n                  <div key={toolCallId}>\n                    {toolName === "displayWeather" ? (\n                      <div>Loading weather...</div>\n                    ) : null}\n                  </div>\n                );\n              }\n            })}\n          </div>\n        </div>\n      ))}\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          placeholder="Type a message"\n        ></input>\n        <button type="submit">Send</button>\n      </form>\n    </div>\n  );\n};\n\nexport default ChatLiteUI;\n\n\n')),(0,r.kt)("h2",{id:"-streaming-custom-data"},"\ud83d\udccc Streaming Custom Data"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("a",{parentName:"p",href:"https://sdk.vercel.ai/docs/ai-sdk-ui/streaming-data#streaming-custom-data"},"https://sdk.vercel.ai/docs/ai-sdk-ui/streaming-data#streaming-custom-data"))),(0,r.kt)("p",null,"\ud750\ub984"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"1.createDataStreamResponse \uc744 \ub9ac\ud134\ud558\uba70 execute\uc548\uc5d0\uc11c streamText\uacfc \uba38\uc9c0\ud55c\ub2e4.  "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"result.mergeIntoDataStream(dataStream);"),"  "),(0,r.kt)("li",{parentName:"ul"},"2.dataStream.writeData : \uc2a4\ud2b8\ub9bc \ub370\uc774\ud130, useChat\uc758 data\uc73c\ub85c \ub118\uc5b4\uc634  "),(0,r.kt)("li",{parentName:"ul"},"3.dataStream.writeMessageAnnotation : \uc2a4\ud2b8\ub9bc \uc5b4\ub178\ud14c\uc774\uc158\ub370\uc774\ud130, \uc8fc\uc11d\uacfc \uac19\uc740 \uba54\ud0c0\uc815\ubcf4 \ub123\ub294\uac83\uc774 \uac00\ub2a5.  useChat\uc758 message \uac1d\uccb4\uc640 \ud568\uaed8 \ub4e4\uc5b4\uc634.  ")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'// app/api/chat-test/route.ts\nimport { openai } from "@ai-sdk/openai";\nimport { generateId, createDataStreamResponse, streamText } from "ai";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  // immediately start streaming (solves RAG issues with status, etc.)\n  return createDataStreamResponse({\n    execute: (dataStream) => {\n      dataStream.writeData("initialized call");\n\n      const result = streamText({\n        model: openai("gpt-4o-mini"),\n        messages,\n        onChunk() {\n          dataStream.writeMessageAnnotation({ chunk: "123" }); // annotation \uc815\ubcf4\ub294 messages\uc548\uc5d0 \ud3ec\ud568\ub418\uba70 \n        },\n        onFinish() {\n          // message annotation:\n          dataStream.writeMessageAnnotation({\n            id: generateId(), // e.g. id from saved DB record\n            other: "information",\n          });\n\n          // call annotation:\n          dataStream.writeData("call completed");\n        },\n      });\n\n      result.mergeIntoDataStream(dataStream);\n    },\n    onError: (error) => {\n      // Error messages are masked by default for security reasons.\n      // If you want to expose the error message to the client, you can do so here:\n      return error instanceof Error ? error.message : String(error);\n    },\n  });\n}\n\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'"use client";\n\nimport { useChat } from "ai/react";\n\nconst ChatLiteUIStreamCustom = () => {\n  const {\n    messages,\n    input,\n    handleInputChange,\n    handleSubmit,\n    data: streamData,\n  } = useChat({\n    api: "/api/chat-test",\n  });\n\n  console.log("messages", messages);\n  console.log("streamData", streamData);\n\n  return (\n    <div>\n      {messages.map((message) => (\n        <div key={message.id}>\n          <div>{message.role === "user" ? "User: " : "AI: "}</div>\n          <div id="content">{message.content}</div>\n          <div id="annotations">\n            {message.annotations && <>{JSON.stringify(message.annotations)}</>}\n          </div>\n        </div>\n      ))}\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          placeholder="Type a message"\n        ></input>\n        <button type="submit">Send</button>\n      </form>\n    </div>\n  );\n};\n\nexport default ChatLiteUIStreamCustom;\n\n')),(0,r.kt)("h3",{id:"eg-\uc2a4\ud06c\ub9bd\ud2b8-\uc694\uc57d\ud558\uae30"},"eg) \uc2a4\ud06c\ub9bd\ud2b8 \uc694\uc57d\ud558\uae30"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"streamText + useCompletion")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'// api/router-hander.ts\nexport async function POST(request: NextRequest) {\n  const body = await request.json(); // { prompt: string }\n\n  const searchParams = request.nextUrl.searchParams;\n\n  const videoId = searchParams.get("video_id");\n\n  if (!videoId) {\n    return NextResponse.json(\n      { error: "\ube44\ub514\uc624 ID\ub97c \ucd94\ucd9c\ud560 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4." },\n      { status: 400 },\n    );\n  }\n\n  const webhookData = await n8nService.getVideoInfo(videoId);\n\n  const result = streamText({\n    model: openai("gpt-4.1-nano"),\n    system: "\ub9c8\ud06c\ub2e4\uc6b4\uc73c\ub85c \uc694\uc57d\ud574\uc918",\n    prompt: webhookData.text_only_ko,\n  });\n\n  return result.toDataStreamResponse();\n}\n---\n// summary.tsx\nimport { Button } from "@/components/ui/button";\nimport { useCompletion } from "@ai-sdk/react";\nimport { Markdown } from "@/components/markdown/markdown";\n\nconst Summary = () => {\n  const { completion, handleSubmit } = useCompletion({\n    initialInput: "initial input", // body.prompt \uac12  \n    initialCompletion: "initial completion", // \ucd08\uae30 LLM \ucd9c\ub825 \ub370\uc774\ud130  \n    api: "http://localhost:3000/api/yt-summary/general-summary?video_id=s5FNl52TIpk",\n    streamProtocol: "data", // streaming data protocol \uc744 \ub530\ub974\ub294\uc9c0 \uc5ec\ubd80  \n  });\n\n  const onClickButton = () => {\n    handleSubmit();\n  };\n\n  return (\n    <div>\n      <Button onClick={onClickButton}>Submit</Button>\n      <Markdown>{completion}</Markdown>\n    </div>\n  );\n};\n\nexport default Summary;\n\n')),(0,r.kt)("h3",{id:"eg-\ub9c8\ud06c-\ub2e4\uc6b4-\ubb38\uc11c-streaming-\uc751\ub2f5"},"eg) \ub9c8\ud06c \ub2e4\uc6b4 \ubb38\uc11c Streaming \uc751\ub2f5"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"streamText + Streaming Custom Data  ")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'          const { fullStream } = await streamText({\n            model: customModel(model.apiIdentifier),\n            system:\n              "Write about the given topic. Markdown is supported. Use headings wherever appropriate.",\n            prompt: title,\n          });\n\n          for await (const delta of fullStream) {\n            const { type } = delta;\n\n            if (type === "text-delta") {\n              const { textDelta } = delta;\n\n              draftText += textDelta;\n              streamingData.append({\n                type: "text-delta",\n                content: textDelta,\n              });\n            }\n          }\n\n          streamingData.append({ type: "finish", content: "" });\n')),(0,r.kt)("h3",{id:"eg-\ubb38\uc11c\ub97c-\ucca8\uc0ad-streaming-object"},"eg) \ubb38\uc11c\ub97c \ucca8\uc0ad Streaming Object"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"stream object + Streaming Custom Data")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'\n          const { elementStream } = await streamObject({\n            model: customModel(model.apiIdentifier),\n            system:\n              "You are a help writing assistant. Given a piece of writing, please offer suggestions to improve the piece of writing and describe the change. It is very important for the edits to contain full sentences instead of just words. Max 5 suggestions.",\n            prompt: document.content,\n            output: "array",\n            schema: z.object({\n              originalSentence: z.string().describe("The original sentence"),\n              suggestedSentence: z.string().describe("The suggested sentence"),\n              description: z\n                .string()\n                .describe("The description of the suggestion"),\n            }),\n          });\n\n          for await (const element of elementStream) {\n            const suggestion = {\n              originalText: element.originalSentence,\n              suggestedText: element.suggestedSentence,\n              description: element.description,\n              id: generateUUID(),\n              documentId: documentId,\n              isResolved: false,\n            };\n\n            streamingData.append({\n              type: "suggestion",\n              content: suggestion,\n            });\n\n            suggestions.push(suggestion);\n          }\n')))}c.isMDXComponent=!0}}]);